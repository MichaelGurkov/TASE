---
title: "Datasets Description"
output: pdf_document
---


```{r setup, include=FALSE,}

knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)

```


```{r load_libraries}

library(devtools)

library(tidyverse)

library(xts)

library(lubridate)

library(stargazer)

library(MiscImport)

load_all()

```

<!-- Import data -->

```{r import_secs_catalog}

secs_catalog = read_csv(paste0(Sys.getenv("USERPROFILE"),
                               "\\OneDrive - Bank Of Israel\\Data",
                               "\\TASE\\Secs_Catalog.csv"),
                        col_types = "cccccccc",
                        show_col_types = FALSE)

vars_list = read_csv(paste0(Sys.getenv("USERPROFILE"),
                            "\\OneDrive - Bank Of Israel\\Data",
                            "\\TASE liquidity\\michael files",
                            "\\Variables_List.csv"),
                     show_col_types = FALSE)


```


```{r import_dates}

del_comps_filepath = paste0(Sys.getenv("USERPROFILE"),
                            "\\OneDrive - Bank Of Israel",
                            "\\Data\\TASE liquidity",
                            "\\michael files\\delisted_comps.csv")

ipo_filepath = paste0(Sys.getenv("USERPROFILE"),
                            "\\OneDrive - Bank Of Israel",
                            "\\Data\\TASE liquidity",
                            "\\michael files\\ipo_dates.csv")

delisted_dates = read_csv(del_comps_filepath,
                          show_col_types = FALSE) %>% 
  arrange(tase_id) %>% 
  mutate(tase_id = as.character(tase_id)) %>% 
  mutate(delisting_date = mdy(delisting_date))

ipo_dates = read_csv(ipo_filepath,
                          show_col_types = FALSE) %>% 
  select(tase_id, ipo_date) %>% 
  mutate(ipo_date = dmy(ipo_date)) %>% 
  mutate(tase_id = as.character(tase_id)) %>% 
  arrange(tase_id)

ipo_and_delisting_dates = ipo_dates %>% 
 full_join(delisted_dates, by = "tase_id") %>% 
  mutate(tase_id = as.character(tase_id)) %>% 
  mutate(quotation_period = difftime(delisting_date, ipo_date)) %>% 
  mutate(quotation_period = time_length(quotation_period,"years")) %>% 
  filter(quotation_period >= 0 | is.na(quotation_period)) %>% 
  arrange(ipo_date)


rm(del_comps_filepath, ipo_filepath, delisted_dates, ipo_dates)

```



# IPO and delisting dates

# Financial reports dataset

```{r finrep_df}

raw_finrep_vars = vars_list %>% 
  filter(data_source == "finrep") %>% 
  filter(category == "raw") %>% 
  pull(df_varname)


final_finrep_vars = vars_list %>% 
  filter(data_source == "finrep") %>% 
  filter(category == "final") %>% 
  pull(df_varname)



finrep_path = paste0(Sys.getenv("USERPROFILE"),
                     "\\OneDrive - Bank Of Israel\\Data",
                     "\\TASE liquidity\\Rdata files\\finrep_full_data",
                     "_2022-11-15.rds")

raw_oracle_finrep_df = import_boi_oracle_finrep_data(finrep_path,
                                          data_frequency = "quarterly")

finrep_df = raw_oracle_finrep_df %>% 
  make_finrep_oracle_df(raw_finrep_vars = raw_finrep_vars,
                        final_finrep_vars = final_finrep_vars)


# rm(finrep_path,raw_finrep_vars,final_finrep_vars,raw_oracle_finrep_df)

```


```{r plot_missing_value_structure}

finrep_df %>% 
  map_dbl(.,~sum(is.na(.)) / length(.)) %>% 
  as_tibble() %>% 
  mutate(col_names = names(finrep_df)) %>% 
  ggplot(aes(value, reorder(col_names, value))) + 
  geom_col() + 
  scale_x_continuous(labels = scales::percent_format()) + 
  xlab(NULL) + ylab(NULL) + ggtitle("Missing structure of finrep df")

```



# Market dataset

```{r Import_market_data}

raw_market_vars = vars_list %>% 
  filter(data_source == "market_data") %>% 
  filter(category == "raw") %>% 
  pull(df_varname)


final_market_vars = vars_list %>% 
  filter(data_source == "market_data") %>% 
  filter(category == "final") %>% 
  filter(!df_varname == "car") %>% 
  pull(df_varname)


market_file_path = paste0(Sys.getenv("USERPROFILE"),
                          "\\OneDrive - Bank Of Israel\\Data",
                          "\\TASE liquidity\\Rdata files",
                          "\\market_data_2022-11-15.rds")


raw_oracle_market_df = import_boi_market_data(market_file_path)

market_df = raw_oracle_market_df %>% 
  make_market_df()

final_market_vars[!final_market_vars %in% names(market_df)]


# rm(market_file_path,raw_oracle_market_df)


```


```{r plot_missing_value_structure}

market_df %>% 
  map_dbl(.,~sum(is.na(.)) / length(.)) %>% 
  as_tibble() %>% 
  mutate(col_names = names(market_df)) %>% 
  ggplot(aes(value, reorder(col_names, value))) + 
  geom_col() + 
  scale_x_continuous(labels = scales::percent_format()) + 
  xlab(NULL) + ylab(NULL) + ggtitle("Missing structure of market df")

```


```{r complete_market_data_from_legacy_data_sources, eval=FALSE}

legacy_market_df = read_rds(paste0(Sys.getenv("USERPROFILE"),
                     "\\OneDrive - Bank Of Israel\\Data",
                     "\\TASE liquidity\\Rdata files\\final_df.RDS")) %>% 
  rename_all(tolower)

legacy_market_df = legacy_market_df %>% 
  rename(size = market_cap_log) %>% 
  select(sec_id, date, any_of(final_market_vars))


```


```{r validation, eval=FALSE}

temp_tase = 1268

temp_sec = read_csv(paste0(Sys.getenv("USERPROFILE"),
                           "\\OneDrive - Bank Of Israel\\Data",
                           "\\TASE liquidity\\michael files\\files_",
                           "from_TASE_website\\",temp_tase,".csv"),
                    show_col_types = FALSE) %>% 
  select(1:2) %>% 
  set_names(c("date","tase_close_adj")) %>% 
  mutate(date = dmy(date))

market_df %>% 
  filter(tase_id == temp_tase) %>% 
  select(date, close) %>% 
  full_join(temp_sec, by = "date") %>% 
  pivot_longer(-date) %>% 
  ggplot(aes(date, value, color = name)) + 
  geom_line()


```



# Final dataset

```{r make_reg_df}

final_vars = vars_list %>% 
  filter(category == "final") %>% 
  filter(status == "present") %>% 
  pull(df_varname)


df = make_reg_df(market_df = market_df,
                 finrep_df = finrep_df,
                 final_vars = final_vars) %>% 
  mutate(across(c(leverage, roa, mb, free_cashflow),
                ~ na_if(., Inf))) %>%
  mutate(across(c(volume, roa,free_cashflow),
                ~ na_if(., -Inf)))

# df = df %>% 
#   filter(date <= as.yearqtr("2020 Q1"))

```

```{r missing_structure}

map_dbl(df,~sum(is.na(.))/length(.)) %>% 
  as_tibble() %>% 
  mutate(col_name = names(df)) %>% 
  ggplot(aes(value, reorder(col_name, value))) + 
  geom_col() + 
  scale_x_continuous(labels = scales::percent_format()) + 
  xlab(NULL) + ylab(NULL) + ggtitle("Missing data in final df")
```

## Complete final dataset from legacy data


```{r Import_legacy_df}


legacy_df = read_rds(paste0(Sys.getenv("USERPROFILE"),
                     "\\OneDrive - Bank Of Israel\\Data",
                     "\\TASE liquidity\\Rdata files\\final_df.RDS")) %>% 
  rename_all(tolower)

legacy_df = legacy_df %>% 
  rename(size = market_cap_log) %>% 
  select(any_of(names(df)))


legacy_df = legacy_df %>% 
  group_by(tase_id, date) %>% 
  summarise(across(everything(), ~mean(., na.rm = TRUE)),
            .groups = "drop")

```



```{r complete_df_with_legacy_df}

df = df %>% 
  pivot_longer(-c("tase_id","date")) %>% 
  left_join(legacy_df %>% 
              pivot_longer(-c("tase_id","date")),
            by = c("tase_id","date","name"), suffix = c("_df","_legacy")) %>% 
  mutate(final_value = coalesce(value_df, value_legacy)) %>% 
  select(-c("value_df","value_legacy")) %>% 
  pivot_wider(id_cols = c("tase_id","date"),
              names_from = "name", values_from = "final_value")

rm(legacy_df)

```


```{r import_nimrod_df}

nimrod_filepath = paste0(Sys.getenv("USERPROFILE"),
                         "\\OneDrive - Bank Of Israel\\Data",
                         "\\TASE liquidity\\Stata files",
                         "\\ahzakot.dta")

nimrod_df = import.nimrod.stata.df(nimrod_filepath)

```




```{r compare_comp, eval=FALSE}

comp_id = "281"

alice = df %>% 
  filter(tase_id == comp_id) %>% 
  select(date, 
  illiq,
  leverage,
  mb,
  turnover)


bob = old_df %>% 
  filter(tase_id == comp_id) %>% 
  select(date, 
  illiq,
  leverage,
  mb,
  turnover)

alice %>% 
  pivot_longer(-date) %>% 
  full_join(bob %>% 
              mutate(across(c("mb","turnover"), ~ .* 10 ^ -6)) %>% 
              pivot_longer(-date) %>% 
              mutate(value = as.numeric(value)),
            by = c("date","name"),
            suffix = c("_alice","_bob")) %>% 
  pivot_longer(cols = starts_with("value"),names_to = "source") %>% 
  ggplot(aes(date, value, color = source)) + 
  geom_line() + 
  facet_wrap(~name, scales = "free")

```





## Save final df

```{r save_final_df, eval=FALSE}

df %>% 
  write_rds(paste0(Sys.getenv("USERPROFILE"),
                   "\\OneDrive - Bank Of Israel\\Data",
                   "\\TASE liquidity\\Rdata files\\final_df_",
                   Sys.Date(),".rds"))

```


# Dataset EDA

```{r Import_data}

del_comps_filepath = paste0(Sys.getenv("USERPROFILE"),
                            "\\OneDrive - Bank Of Israel",
                            "\\Data\\TASE liquidity",
                            "\\michael files\\delisted_comps.csv")

ipo_filepath = paste0(Sys.getenv("USERPROFILE"),
                            "\\OneDrive - Bank Of Israel",
                            "\\Data\\TASE liquidity",
                            "\\michael files\\ipo_dates.csv")

comps_dates = import_comps_dates_and_status(ipo_filepath,
                                            del_comps_filepath) %>% 
  filter(!tase_id %in% c("1286","1701"))


df = read_rds(paste0(Sys.getenv("USERPROFILE"),
                     "\\OneDrive - Bank Of Israel\\Data",
                     "\\TASE liquidity\\Rdata files",
                     "\\final_df_2022-11-20.rds"))


matched_df = get_matched_df(df, comps_dates,
                            matching_variable = "size",
                            threshold = 0.15)
  
  
rm(del_comps_filepath, ipo_filepath)


```

## IPO

```{r import_ta_125}

ta_125_old = read_csv(paste0(Sys.getenv("USERPROFILE"),
                             "\\OneDrive - Bank Of Israel\\Data\\BoI",
                             "\\Stocks\\stocks_index.csv"),
                      show_col_types = FALSE) %>% 
  select(date, ta_125) %>% 
  mutate(date = dmy(date)) %>% 
  filter(complete.cases(.))

ta_125 = read_csv(paste0(Sys.getenv("USERPROFILE"),
                         "\\OneDrive - Bank Of Israel",
                         "\\Data\\TASE liquidity",
                         "\\michael files\\TA125.csv"),
                  show_col_types = FALSE,
                  col_names = c("date","basis","open",
                                "close","hi","low","market_cap"),
                  skip = 1) %>% 
  select(date, ta_125 = close) %>% 
  mutate(date = dmy(date)) %>% 
  filter(complete.cases(.))

ta_125 = ta_125 %>% 
  full_join(ta_125_old, by = "date",
            suffix = c("_new","_old")) %>% 
  mutate(ta_125 = coalesce(ta_125_new, ta_125_old)) %>% 
  select(date, ta_125)

rm(ta_125_old)


```


```{r market_df}


market_file_path = paste0(Sys.getenv("USERPROFILE"),
                          "\\OneDrive - Bank Of Israel\\Data",
                          "\\TASE liquidity\\Rdata files",
                          "\\market_data_2022-11-15.rds")


market_df  = import_boi_market_data(market_file_path) %>% 
  filter(!is.na(close))

rm(market_file_path)






```

```{r make_ret_for_all_comps_df}

calculate_return = function(price, days_diff){
  
  ret_gross =  price / price[days_diff == 0]
  
  ret_annulized = ret_gross ^ (365 / as.numeric(days_diff)) - 1
  
  return(ret_annulized)
                               
                               
  
}

# ret_for_all_comps_df = market_df %>% 
#   select(tase_id, sec_id, date, close) %>% 
#   left_join(ta_125, by = "date") %>% 
#   group_by(tase_id, sec_id) %>% 
#   arrange(date) %>% 
#   mutate(trade_dur = date - min(date)) %>% 
#   mutate(across(c("close","ta_125"),
#                 .fns = ~ calculate_return(price = .,
#                                           days_diff = trade_dur),
#                 .names = "{col}_ret")) %>% 
#   select(-c("close","ta_125")) %>% 
#   ungroup() %>% 
#   mutate(market_adj_ret = close_ret - ta_125_ret)

# ret_for_all_comps_df %>% 
#   write_rds(paste0(Sys.getenv("USERPROFILE"),
#                           "\\OneDrive - Bank Of Israel\\Data",
#                           "\\TASE liquidity\\Rdata files",
#                           "\\ret_for_all_comps_df.rds"))

rm(calculate_return)




```

```{r ret_df_for_all}

ret_for_all_comps_df = read_rds(paste0(
  Sys.getenv("USERPROFILE"),
  "\\OneDrive - Bank Of Israel\\Data",
  "\\TASE liquidity\\Rdata files",
  "\\ret_for_all_comps_df.rds"))


# ret_for_all_comps_df = write_rds(paste0(
#   Sys.getenv("USERPROFILE"),
#   "\\OneDrive - Bank Of Israel\\Data",
#   "\\TASE liquidity\\Rdata files",
#   "\\ret_for_all_comps_df.rds"))


```


```{r check_first_dates_against_ipo}

temp = market_df %>% 
  group_by(tase_id) %>% 
  summarise(date = min(date), .groups = "drop") %>% 
  left_join(ipo_and_delisting_dates %>% 
              group_by(tase_id) %>% 
              summarise(ipo_date = min(ipo_date), .groups = "drop"),
            by = "tase_id") %>% 
  mutate(days_diff = date - ipo_date)

```

```{r average_3_year_market_adjusted_returns}



ret_df = market_df %>% 
  select(sec_id, tase_id, date, close) %>% 
  filter(!is.na(close)) %>% 
  left_join(ta_125, by = "date") %>% 
  group_by(sec_id, tase_id) %>% 
  arrange(date) %>% 
  mutate(days_diff = date - min(date)) %>% 
  filter(days_diff == 0 | days_diff %in% 1090:1100) %>% 
  slice(1, length(date)) %>% 
  summarise(sec_ret = (close[2] / close[1] - 1) / 3,
            sec_ret_adj = ((close[2] / close[1] - 1) -  
              (ta_125[2] / ta_125[1] - 1))/ 3,
            .groups = "drop")

ret_df = ret_df %>% 
  left_join(market_df %>% 
              group_by(tase_id, sec_id) %>% 
              summarise(first_date = min(date), .groups = "drop"),
            by = c("tase_id","sec_id"))

rm(ta_125)

```

```{r average_style_adjusted_returns}

style_matched_comps = market_df %>% 
  select(tase_id,sec_id, date, market_value) %>% 
  filter(!is.na(market_value)) %>% 
  group_by(tase_id,sec_id) %>% 
  arrange(date) %>%
  slice(1) %>% 
  ungroup() %>% 
  left_join(market_df %>% 
              select(tase_id,sec_id, date, market_value) %>% 
              filter(!is.na(market_value)),
            by = "date", suffix = c("_ipo","_control")) %>% 
  group_by(tase_id_ipo, sec_id_ipo) %>% 
  mutate(market_diff = abs(market_value_control - market_value_ipo)) %>% 
  mutate(market_diff = market_diff / (market_value_control +
                                        market_value_ipo)) %>% 
  arrange(market_diff) %>% 
  slice(2) %>% 
  ungroup() %>% 
  filter(market_diff < 0.2) %>%
  select(tase_id_ipo,sec_id_ipo, tase_id_control, sec_id_control)

control_comps_with_first_dates = style_matched_comps %>% 
  left_join(ret_df %>% 
              select(tase_id, sec_id, first_date),
            by = c("tase_id_ipo" = "tase_id",
                   "sec_id_ipo" = "sec_id"))



style_ret = market_df %>% 
  filter(!is.na(close)) %>% 
  select(tase_id, sec_id, date, close) %>% 
  inner_join(control_comps_with_first_dates,
             by = c("tase_id" = "tase_id_control",
                    "sec_id" = "sec_id_control")) %>% 
  group_by(tase_id, sec_id, tase_id_ipo, sec_id_ipo) %>% 
  arrange(date) %>% 
  mutate(days_diff = date - first_date) %>% 
  filter(days_diff == 0 | days_diff %in% 1090:1100) %>% 
  slice(1, length(close)) %>% 
  summarise(sec_ret_style = (close[2] / close[1] - 1) / 3, .groups = "drop")



ret_df = ret_df %>% 
  left_join(style_ret %>% 
              select(tase_id = tase_id_ipo,
                     sec_id = sec_id_ipo,
                     sec_ret_style),
            by = c("tase_id", "sec_id")) %>% 
  mutate(sec_ret_style = sec_ret - sec_ret_style)

rm(style_matched_comps, style_ret,control_comps_with_first_dates)

```


```{r plot_ipo_long_run_performance}

ret_df %>% 
  mutate(year = year(first_date)) %>% 
  select(year, contains("ret")) %>% 
  pivot_longer(-year) %>% 
  filter(!is.na(value)) %>% 
  group_by(year, name) %>% 
  summarise(value = median(value), .groups = "drop") %>% 
  filter(year >= 2000) %>% 
  ggplot(aes(as.character(year), value)) + 
  geom_col(aes(fill = name), position = "dodge")  + 
  scale_y_continuous(labels = scales::percent_format()) + 
  xlab(NULL) + ylab(NULL) + 
  theme(legend.title = element_blank()) + 
  ggtitle("Long run performance of IPO comps")


ret_df %>% 
  mutate(year = year(first_date)) %>% 
  select(year, contains("ret")) %>% 
  pivot_longer(-year) %>% 
  filter(!is.na(value)) %>% 
  group_by(year, name) %>% 
  summarise(value = median(value), .groups = "drop") %>% 
  filter(year >= 2000) %>% 
  pivot_wider() %>% 
  write_csv(paste0("C:\\Users\\Home",
                   "\\OneDrive - Bank Of Israel\\current_work",
                   "\\annual_report\\2022",
                   "\\data\\plots\\long_run_ipo.csv"))


```



```{r check_return_for_temp_tase_id, eval=FALSE}

temp_tase_id = "1363"

temp_price_df = market_df %>% 
  filter(!is.na(close)) %>% 
  filter(tase_id == temp_tase_id) %>% 
  arrange(date)

temp_price_df %>% 
  ggplot(aes(date,close)) + 
  geom_line()

temp_first_market_price_date = min(temp_price_df$date)

temp_last_market_price_date = max(which((temp_price_df$date - min(temp_price_df$date)) <= 365 * 3))

temp_last_market_price_date = temp_price_df$date[temp_last_market_price_date]

temp_ret = temp_price_df %>% 
  filter(date %in% c(temp_first_market_price_date,
                     temp_last_market_price_date)) %>% 
  summarise(ret = c(close[2] / close[1] - 1) / 3) %>% 
  pull(ret)

all.equal(ret_df %>% 
  filter(tase_id == temp_tase_id) %>% 
    pull(sec_ret), temp_ret)

rm(list = str_subset(ls(), "temp"))


```

```{r check_market_adjusted_return_for_temp_tase_id, eval=FALSE}

temp_tase_id = "1363"

temp_price_df = market_df %>% 
  filter(!is.na(close)) %>% 
  filter(tase_id == temp_tase_id) %>% 
  arrange(date)

temp_first_market_price_date = min(temp_price_df$date)

temp_last_market_price_date = max(which((temp_price_df$date - min(temp_price_df$date)) <= 365 * 3))

temp_last_market_price_date = temp_price_df$date[temp_last_market_price_date]

temp_ret = temp_price_df %>% 
  filter(date %in% c(temp_first_market_price_date,
                     temp_last_market_price_date)) %>% 
  summarise(ret = c(close[2] / close[1] - 1) / 3) %>% 
  pull(ret)

temp_market_ret = ta_125 %>% 
  arrange(date) %>% 
  filter(date %in% c(temp_first_market_price_date,
                     temp_last_market_price_date)) %>% 
  summarise(ret = c(ta_125[2] / ta_125[1] - 1) / 3) %>% 
  pull(ret)

all.equal(ret_df %>% 
  filter(tase_id == temp_tase_id) %>% 
    pull(sec_ret_adj), (temp_ret - temp_market_ret))

rm(list = str_subset(ls(), "temp"))


```


```{r check_style_return_for_temp_tase_id, eval=FALSE}

temp_tase_id_ipo = "1363"

temp_price_df_ipo = market_df %>% 
  filter(!is.na(close)) %>% 
  filter(tase_id == temp_tase_id_ipo) %>% 
  arrange(date)

temp_market = temp_price_df_ipo %>% 
  select(tase_id, date, market_value) %>% 
  arrange(date) %>% 
  slice(1) %>% 
  left_join(market_df %>% 
              select(tase_id, date, market_value),
            by = "date", suffix = c("_ipo","_control")) %>% 
  mutate(market_diff = abs(market_value_ipo - market_value_control)) %>% 
  mutate(market_diff = market_diff / (market_value_ipo +
                                        market_value_control)) %>% 
  arrange(market_diff) %>% 
  slice(2) %>% 
  select(tase_id_ipo,tase_id_control)
  

temp_first_date_ipo = min(temp_price_df_ipo$date)

temp_last_date_ipo = max(which((temp_price_df_ipo$date - min(temp_price_df_ipo$date)) %in% 1090:1100))

temp_last_date_ipo = temp_price_df_ipo$date[temp_last_date_ipo]

temp_ret_ipo = temp_price_df_ipo %>% 
  filter(date %in% c(temp_first_date_ipo,
                     temp_last_date_ipo)) %>% 
  summarise(ret = c(close[2] / close[1] - 1) / 3) %>% 
  pull(ret)

# Control ret

temp_price_df_control = market_df %>% 
  filter(!is.na(close)) %>% 
  filter(tase_id == temp_market$tase_id_control) %>% 
  arrange(date)

temp_first_date_control = temp_first_date_ipo

temp_last_date_control = max(which((temp_price_df_control$date - temp_first_date_control) %in% 1090:1100))

temp_last_date_control = temp_price_df_control$date[temp_last_date_control]

temp_ret_control = temp_price_df_control %>% 
  filter(date %in% c(temp_first_date_control,
                     temp_last_date_control)) %>% 
  summarise(ret = c(close[2] / close[1] - 1) / 3) %>% 
  pull(ret)


all.equal(ret_df %>% 
  filter(tase_id == temp_tase_id_ipo) %>% 
    pull(sec_ret_style), temp_ret_ipo - temp_ret_control)

rm(list = str_subset(ls(), "temp"))


```


## Delisted comps

```{r get_delisted_comps_df}

delisted_comps_df = df %>% 
  inner_join(comps_dates %>% 
  filter(!is.na(delisting_date)) %>% 
  select(tase_id) %>% 
  distinct(), by = "tase_id")
  

```

```{r box_plot}

delisted_comps_df %>% 
  select(-total_assets, -intangible_assets) %>% 
  pivot_longer(-c(tase_id, date)) %>% 
  filter(complete.cases(.)) %>% 
  filter(is.finite(value)) %>%
  group_by(name) %>% 
  filter(value >= quantile(value,0.1) & 
         value <= quantile(value,0.9)) %>% 
  ungroup() %>% 
  group_by(tase_id, name) %>% 
  summarise(value = mean(value, na.rm = TRUE), .groups = "drop") %>% 
  ggplot(aes(y = value)) + 
  geom_boxplot() + 
  facet_wrap(~name, scales = "free")

```

```{r delisted_comps_by_roa}

delisted_comps_df %>% 
  filter(is.finite(roa)) %>% 
  group_by(tase_id) %>% 
  summarise(avg_roa = mean(roa, na.rm = TRUE),
            .groups = "drop") %>% 
  ggplot(aes(x = avg_roa, y = reorder(tase_id, avg_roa))) + 
  geom_col() + 
  xlab(NULL) + ylab(NULL)

delisted_comps_df %>% 
  filter(is.finite(roa)) %>% 
  group_by(tase_id) %>% 
  summarise(avg_roa = mean(roa, na.rm = TRUE),
            .groups = "drop") %>% 
  filter(avg_roa < -2) %>% 
  pull(tase_id) %>% 
  unique()


```

```{r plot_comp_status}

delisted_comps_df %>% 
  filter(tase_id == 1595) %>% 
  pivot_longer(-c(tase_id, date)) %>% 
  ggplot(aes(date, value)) + 
  geom_line() + 
  facet_wrap(~name, scales = "free") + 
  xlab(NULL) + ylab(NULL)

```


```{r get_delisted_comps_market_df}

market_file_path = paste0(Sys.getenv("USERPROFILE"),
                          "\\OneDrive - Bank Of Israel\\Data",
                          "\\TASE liquidity\\Rdata files",
                          "\\market_data_2022-11-15.rds")


delisted_ret_df = import_boi_market_data(market_file_path) %>% 
  inner_join(delisted_dates %>% 
               select(tase_id) %>% 
               mutate(tase_id = as.character(tase_id)) %>% 
               distinct(), by = "tase_id") %>% 
  select(sec_id, tase_id, date, close)

delisted_ret_df = delisted_ret_df%>% 
  group_by(sec_id) %>% 
  arrange(date) %>% 
  mutate(sec_ret = c(NA, diff(log(close)))) %>% 
  ungroup()

rm(market_file_path)


```


```{r}

delisted_ret_df %>% 
  group_by(sec_id) %>% 
  summarise(avg_ret = mean(sec_ret, na.rm = TRUE), .groups = "drop") %>% 
  ggplot(aes(x = avg_ret)) + 
  geom_histogram()
  


```

