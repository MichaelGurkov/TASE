---
title: "Datasets Description"
output: pdf_document
---


```{r setup, include=FALSE,}

knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)

```


```{r load_libraries}

library(devtools)

library(tidyverse)

library(xts)

library(lubridate)

library(stargazer)

library(MiscImport)

load_all()

```

<!-- Import data -->

```{r import_secs_catalog}

secs_catalog = read_csv(paste0(Sys.getenv("USERPROFILE"),
                               "\\OneDrive - Bank Of Israel\\Data",
                               "\\TASE\\Secs_Catalog.csv"),
                        col_types = "cccccccc",
                        show_col_types = FALSE)

vars_list = read_csv(paste0(Sys.getenv("USERPROFILE"),
                            "\\OneDrive - Bank Of Israel\\Data",
                            "\\TASE liquidity\\michael files",
                            "\\Variables_List.csv"),
                     show_col_types = FALSE)


```

# IPO and delisting dates

```{r import_dates}

del_comps_filepath = paste0(Sys.getenv("USERPROFILE"),
                            "\\OneDrive - Bank Of Israel",
                            "\\Data\\TASE liquidity",
                            "\\michael files\\delisted_comps.csv")

ipo_filepath = paste0(Sys.getenv("USERPROFILE"),
                            "\\OneDrive - Bank Of Israel",
                            "\\Data\\TASE liquidity",
                            "\\michael files\\ipo_dates.csv")

delisted_dates = read_csv(del_comps_filepath,
                          show_col_types = FALSE) %>% 
  arrange(tase_id) %>% 
  mutate(delisting_date = mdy(delisting_date))

ipo_dates = read_csv(ipo_filepath,
                          show_col_types = FALSE) %>% 
  select(tase_id, ipo_date) %>% 
  mutate(ipo_date = dmy(ipo_date)) %>% 
  mutate(tase_id = as.character(tase_id)) %>% 
  arrange(tase_id)

delisted_comps = ipo_dates %>% 
 full_join(delisted_dates, by = "tase_id") %>% 
  mutate(tase_id = as.character(tase_id)) %>% 
  mutate(quotation_period = difftime(delisting_date, ipo_date)) %>% 
  mutate(quotation_period = time_length(quotation_period,"years")) %>% 
  filter(quotation_period >= 0) %>% 
  arrange(ipo_date) %>% 
  filter(year(ipo_date) >= 2005)


rm(del_comps_filepath, ipo_filepath)

```


# Financial reports dataset

```{r finrep_df}

raw_finrep_vars = vars_list %>% 
  filter(data_source == "finrep") %>% 
  filter(category == "raw") %>% 
  pull(df_varname)


final_finrep_vars = vars_list %>% 
  filter(data_source == "finrep") %>% 
  filter(category == "final") %>% 
  pull(df_varname)



finrep_path = paste0(Sys.getenv("USERPROFILE"),
                     "\\OneDrive - Bank Of Israel\\Data",
                     "\\TASE liquidity\\Rdata files\\finrep_full_data",
                     "_2022-11-15.rds")

raw_oracle_finrep_df = import_boi_oracle_finrep_data(finrep_path,
                                          data_frequency = "quarterly")

finrep_df = raw_oracle_finrep_df %>% 
  make_finrep_oracle_df(raw_finrep_vars = raw_finrep_vars,
                        final_finrep_vars = final_finrep_vars)


# rm(finrep_path,raw_finrep_vars,final_finrep_vars,raw_oracle_finrep_df)

```


```{r plot_missing_value_structure}

finrep_df %>% 
  map_dbl(.,~sum(is.na(.)) / length(.)) %>% 
  as_tibble() %>% 
  mutate(col_names = names(finrep_df)) %>% 
  ggplot(aes(value, reorder(col_names, value))) + 
  geom_col() + 
  scale_x_continuous(labels = scales::percent_format()) + 
  xlab(NULL) + ylab(NULL) + ggtitle("Missing structure of finrep df")

```



# Market dataset

```{r Import_market_data}

raw_market_vars = vars_list %>% 
  filter(data_source == "market_data") %>% 
  filter(category == "raw") %>% 
  pull(df_varname)


final_market_vars = vars_list %>% 
  filter(data_source == "market_data") %>% 
  filter(category == "final") %>% 
  filter(!df_varname == "car") %>% 
  pull(df_varname)


market_file_path = paste0(Sys.getenv("USERPROFILE"),
                          "\\OneDrive - Bank Of Israel\\Data",
                          "\\TASE liquidity\\Rdata files",
                          "\\market_data_2022-11-15.rds")


raw_oracle_market_df = import_boi_market_data(market_file_path)

market_df = raw_oracle_market_df %>% 
  make_market_df()

final_market_vars[!final_market_vars %in% names(market_df)]


# rm(market_file_path,raw_oracle_market_df)


```


```{r plot_missing_value_structure}

market_df %>% 
  map_dbl(.,~sum(is.na(.)) / length(.)) %>% 
  as_tibble() %>% 
  mutate(col_names = names(market_df)) %>% 
  ggplot(aes(value, reorder(col_names, value))) + 
  geom_col() + 
  scale_x_continuous(labels = scales::percent_format()) + 
  xlab(NULL) + ylab(NULL) + ggtitle("Missing structure of market df")

```


```{r complete_market_data_from_legacy_data_sources, eval=FALSE}

legacy_market_df = read_rds(paste0(Sys.getenv("USERPROFILE"),
                     "\\OneDrive - Bank Of Israel\\Data",
                     "\\TASE liquidity\\Rdata files\\final_df.RDS")) %>% 
  rename_all(tolower)

legacy_market_df = legacy_market_df %>% 
  rename(size = market_cap_log) %>% 
  select(sec_id, date, any_of(final_market_vars))


```



# Final dataset

```{r make_reg_df}

final_vars = vars_list %>% 
  filter(category == "final") %>% 
  filter(status == "present") %>% 
  pull(df_varname)


df = make_reg_df(market_df = market_df,
                 finrep_df = finrep_df,
                 final_vars = final_vars) %>% 
  mutate(across(c(leverage, roa, mb, free_cashflow),
                ~ na_if(., Inf))) %>%
  mutate(across(c(volume, roa,free_cashflow),
                ~ na_if(., -Inf)))

# df = df %>% 
#   filter(date <= as.yearqtr("2020 Q1"))

```

```{r missing_structure}

map_dbl(df,~sum(is.na(.))/length(.)) %>% 
  as_tibble() %>% 
  mutate(col_name = names(df)) %>% 
  ggplot(aes(value, reorder(col_name, value))) + 
  geom_col() + 
  scale_x_continuous(labels = scales::percent_format()) + 
  xlab(NULL) + ylab(NULL) + ggtitle("Missing data in final df")
```

## Complete final dataset from legacy data


```{r Import_legacy_df}


legacy_df = read_rds(paste0(Sys.getenv("USERPROFILE"),
                     "\\OneDrive - Bank Of Israel\\Data",
                     "\\TASE liquidity\\Rdata files\\final_df.RDS")) %>% 
  rename_all(tolower)

legacy_df = legacy_df %>% 
  rename(size = market_cap_log) %>% 
  select(any_of(names(df)))


legacy_df = legacy_df %>% 
  group_by(tase_id, date) %>% 
  summarise(across(everything(), ~mean(., na.rm = TRUE)),
            .groups = "drop")

```



```{r complete_df_with_legacy_df}

df = df %>% 
  pivot_longer(-c("tase_id","date")) %>% 
  left_join(legacy_df %>% 
              pivot_longer(-c("tase_id","date")),
            by = c("tase_id","date","name"), suffix = c("_df","_legacy")) %>% 
  mutate(final_value = coalesce(value_df, value_legacy)) %>% 
  select(-c("value_df","value_legacy")) %>% 
  pivot_wider(id_cols = c("tase_id","date"),
              names_from = "name", values_from = "final_value")

rm(legacy_df)

```


```{r import_nimrod_df}

nimrod_filepath = paste0(Sys.getenv("USERPROFILE"),
                         "\\OneDrive - Bank Of Israel\\Data",
                         "\\TASE liquidity\\Stata files",
                         "\\ahzakot.dta")

nimrod_df = import.nimrod.stata.df(nimrod_filepath)

```




```{r compare_comp, eval=FALSE}

comp_id = "281"

alice = df %>% 
  filter(tase_id == comp_id) %>% 
  select(date, 
  illiq,
  leverage,
  mb,
  turnover)


bob = old_df %>% 
  filter(tase_id == comp_id) %>% 
  select(date, 
  illiq,
  leverage,
  mb,
  turnover)

alice %>% 
  pivot_longer(-date) %>% 
  full_join(bob %>% 
              mutate(across(c("mb","turnover"), ~ .* 10 ^ -6)) %>% 
              pivot_longer(-date) %>% 
              mutate(value = as.numeric(value)),
            by = c("date","name"),
            suffix = c("_alice","_bob")) %>% 
  pivot_longer(cols = starts_with("value"),names_to = "source") %>% 
  ggplot(aes(date, value, color = source)) + 
  geom_line() + 
  facet_wrap(~name, scales = "free")

```





## Save final df

```{r save_final_df, eval=FALSE}

df %>% 
  write_rds(paste0(Sys.getenv("USERPROFILE"),
                   "\\OneDrive - Bank Of Israel\\Data",
                   "\\TASE liquidity\\Rdata files\\final_df_",
                   Sys.Date(),".rds"))

```


# Dataset EDA

```{r Import_data}

del_comps_filepath = paste0("C:\\Users\\internet",
                            "\\OneDrive - Bank Of Israel",
                            "\\Data\\TASE liquidity",
                            "\\michael files\\delisted_comps.csv")

ipo_filepath = paste0("C:\\Users\\internet",
                            "\\OneDrive - Bank Of Israel",
                            "\\Data\\TASE liquidity",
                            "\\michael files\\ipo_dates.csv")

comps_dates = import_comps_dates_and_status(ipo_filepath,
                                            del_comps_filepath) %>% 
  filter(!tase_id %in% c("1286","1701"))


df = read_rds(paste0("C:\\Users\\internet",
                     "\\OneDrive - Bank Of Israel\\Data",
                     "\\TASE liquidity\\Rdata files",
                     "\\final_df_2022-11-20.rds"))


matched_df = get_matched_df(df, comps_dates,
                            matching_variable = "size",
                            threshold = 0.15)
  
  
rm(del_comps_filepath, ipo_filepath)


```

## IPO

```{r ipo_price_df}


market_file_path = paste0(Sys.getenv("USERPROFILE"),
                          "\\OneDrive - Bank Of Israel\\Data",
                          "\\TASE liquidity\\Rdata files",
                          "\\market_data_2022-11-15.rds")


ipo_price_df = import_boi_market_data(market_file_path) %>% 
  inner_join(ipo_dates %>% 
               select(tase_id) %>% 
               mutate(tase_id = as.character(tase_id)) %>% 
               distinct(), by = "tase_id") %>% 
  select(sec_id, tase_id, date, close)


rm(market_file_path)


```

```{r average_3_year_returns}

ipo_ret_df = ipo_price_df %>% 
  left_join(ipo_dates, by = "tase_id") %>% 
  mutate(days_diff = date - ipo_date) %>% 
  filter(days_diff < 365) %>% 
  group_by(sec_id, tase_id, ipo_date) %>% 
  arrange(date) %>% 
  slice(1, length(date)) %>% 
  summarise(sec_ret = (close[2] / close[1] - 1) / 3, .groups = "drop")

ipo_ret_df %>% 
  filter(complete.cases(.)) %>% 
  filter(sec_ret <= quantile(sec_ret, 0.95)) %>% 
  group_by(year = year(ipo_date)) %>% 
  summarise(avg_ret = mean(sec_ret), .groups = "drop") %>% 
  ggplot(aes(x = year, y = avg_ret)) + 
  geom_col(aes(fill = (avg_ret >= 0)), show.legend = FALSE) + 
  scale_y_continuous(labels = scales::percent_format()) + 
  xlab(NULL) + ylab(NULL) + ggtitle("Average 3 years returns of IPO firms")

```

```{r average_3_year_market_adjusted_returns}

ta_125 = read_csv(paste0(Sys.getenv("USERPROFILE"),
                         "\\OneDrive - Bank Of Israel",
                         "\\Data\\TASE liquidity",
                         "\\michael files\\TA125.csv"),
                  show_col_types = FALSE,
                  col_names = c("date","basis","open",
                                "close","hi","low","market_cap"),
                  skip = 1) %>% 
  select(date, ta_125 = close) %>% 
  mutate(date = dmy(date))


ipo_ret__adj_df = ipo_price_df %>% 
  left_join(ta_125, by = "date") %>% 
  left_join(ipo_dates, by = "tase_id") %>% 
  mutate(days_diff = date - ipo_date) %>% 
  filter(days_diff < 365) %>% 
  group_by(sec_id, tase_id, ipo_date) %>% 
  arrange(date) %>% 
  slice(1, length(date)) %>% 
  summarise(sec_ret_adj = (close[2] / close[1] - 1) -  
              (ta_125[2] / ta_125[1] - 1)/ 3, .groups = "drop")



ipo_ret__adj_df %>% 
  filter(complete.cases(.)) %>% 
  filter(sec_ret_adj <= quantile(sec_ret_adj, 0.95)) %>% 
  group_by(year = year(ipo_date)) %>% 
  summarise(avg_ret = mean(sec_ret_adj), .groups = "drop") %>% 
  ggplot(aes(x = year, y = avg_ret)) + 
  geom_col(aes(fill = (avg_ret >= 0)), show.legend = FALSE) + 
  scale_y_continuous(labels = scales::percent_format()) + 
  xlab(NULL) + ylab(NULL) + 
  ggtitle("Average 3 years market adjusted returns of IPO firms")



```


## Delisted comps

```{r get_delisted_comps_df}

delisted_comps_df = df %>% 
  inner_join(comps_dates %>% 
  filter(!is.na(delisting_date)) %>% 
  select(tase_id) %>% 
  distinct(), by = "tase_id")
  

```

```{r box_plot}

delisted_comps_df %>% 
  select(-total_assets, -intangible_assets) %>% 
  pivot_longer(-c(tase_id, date)) %>% 
  filter(complete.cases(.)) %>% 
  filter(is.finite(value)) %>%
  group_by(name) %>% 
  filter(value >= quantile(value,0.1) & 
         value <= quantile(value,0.9)) %>% 
  ungroup() %>% 
  group_by(tase_id, name) %>% 
  summarise(value = mean(value, na.rm = TRUE), .groups = "drop") %>% 
  ggplot(aes(y = value)) + 
  geom_boxplot() + 
  facet_wrap(~name, scales = "free")

```

```{r delisted_comps_by_roa}

delisted_comps_df %>% 
  filter(is.finite(roa)) %>% 
  group_by(tase_id) %>% 
  summarise(avg_roa = mean(roa, na.rm = TRUE),
            .groups = "drop") %>% 
  ggplot(aes(x = avg_roa, y = reorder(tase_id, avg_roa))) + 
  geom_col() + 
  xlab(NULL) + ylab(NULL)

delisted_comps_df %>% 
  filter(is.finite(roa)) %>% 
  group_by(tase_id) %>% 
  summarise(avg_roa = mean(roa, na.rm = TRUE),
            .groups = "drop") %>% 
  filter(avg_roa < -2) %>% 
  pull(tase_id) %>% 
  unique()


```

```{r plot_comp_status}

delisted_comps_df %>% 
  filter(tase_id == 1595) %>% 
  pivot_longer(-c(tase_id, date)) %>% 
  ggplot(aes(date, value)) + 
  geom_line() + 
  facet_wrap(~name, scales = "free") + 
  xlab(NULL) + ylab(NULL)

```


```{r get_delisted_comps_market_df}

market_file_path = paste0(Sys.getenv("USERPROFILE"),
                          "\\OneDrive - Bank Of Israel\\Data",
                          "\\TASE liquidity\\Rdata files",
                          "\\market_data_2022-11-15.rds")


delisted_ret_df = import_boi_market_data(market_file_path) %>% 
  inner_join(delisted_dates %>% 
               select(tase_id) %>% 
               mutate(tase_id = as.character(tase_id)) %>% 
               distinct(), by = "tase_id") %>% 
  select(sec_id, tase_id, date, close)

delisted_ret_df = delisted_ret_df%>% 
  group_by(sec_id) %>% 
  arrange(date) %>% 
  mutate(sec_ret = c(NA, diff(log(close)))) %>% 
  ungroup()

rm(market_file_path)


```


```{r}

delisted_ret_df %>% 
  group_by(sec_id) %>% 
  summarise(avg_ret = mean(sec_ret, na.rm = TRUE), .groups = "drop") %>% 
  ggplot(aes(x = avg_ret)) + 
  geom_histogram()
  


```

